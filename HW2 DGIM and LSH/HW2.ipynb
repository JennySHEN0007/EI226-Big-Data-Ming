{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accompanied-circle",
   "metadata": {
    "papermill": {
     "duration": 0.015941,
     "end_time": "2021-04-25T17:16:03.860597",
     "exception": false,
     "start_time": "2021-04-25T17:16:03.844656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* > # EE226 - Coding 2\n",
    "## Streaming algorithm & Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-soccer",
   "metadata": {
    "papermill": {
     "duration": 0.01336,
     "end_time": "2021-04-25T17:16:03.887872",
     "exception": false,
     "start_time": "2021-04-25T17:16:03.874512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Streaming: DGIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-regression",
   "metadata": {
    "papermill": {
     "duration": 0.01334,
     "end_time": "2021-04-25T17:16:03.915333",
     "exception": false,
     "start_time": "2021-04-25T17:16:03.901993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "DGIM is an efficient algorithm in processing large streams. When it's infeasible to store the flowing binary stream, DGIM can estimate the number of 1-bits in the window. In this coding, you're given the *stream_data.txt* (binary stream), and you need to implement the DGIM algorithm to count the number of 1-bits. Write code and ask the problems below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-share",
   "metadata": {
    "papermill": {
     "duration": 0.014212,
     "end_time": "2021-04-25T17:16:03.943151",
     "exception": false,
     "start_time": "2021-04-25T17:16:03.928939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-fashion",
   "metadata": {
    "papermill": {
     "duration": 0.013053,
     "end_time": "2021-04-25T17:16:03.969870",
     "exception": false,
     "start_time": "2021-04-25T17:16:03.956817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Set the window size to 1000, and count the number of 1-bits in the current window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nasty-mailing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:16:04.002662Z",
     "iopub.status.busy": "2021-04-25T17:16:04.000789Z",
     "iopub.status.idle": "2021-04-25T17:16:12.221910Z",
     "shell.execute_reply": "2021-04-25T17:16:12.220750Z"
    },
    "papermill": {
     "duration": 8.239021,
     "end_time": "2021-04-25T17:16:12.222112",
     "exception": false,
     "start_time": "2021-04-25T17:16:03.983091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in /opt/conda/lib/python3.7/site-packages (0.58.0)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from memory_profiler) (5.8.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outer-craps",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:16:12.273108Z",
     "iopub.status.busy": "2021-04-25T17:16:12.268047Z",
     "iopub.status.idle": "2021-04-25T17:16:13.371827Z",
     "shell.execute_reply": "2021-04-25T17:16:13.371148Z"
    },
    "papermill": {
     "duration": 1.134908,
     "end_time": "2021-04-25T17:16:13.372031",
     "exception": false,
     "start_time": "2021-04-25T17:16:12.237123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 1-bits in the current window using DGIM: 508.0\n",
      "CPU times: user 196 ms, sys: 0 ns, total: 196 ms\n",
      "Wall time: 196 ms\n",
      "peak memory: 172.88 MiB, increment: 0.18 MiB\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "%load_ext memory_profiler\n",
    "filename=\"../input/coding2/stream_data.txt\"\n",
    "\n",
    "windowsize=1000\n",
    "timestamp=0\n",
    "buckets_list=[]\n",
    "\n",
    "# ws=windowsize,ts=timestamp,bl=buckets_list[]\n",
    "def update_buckets_list(ws,ts,bl):\n",
    "    if len(bl)>0 and ts-ws==bl[0][\"timestamp\"]: # drop the oldest bucket\n",
    "        del bl[0]\n",
    "    for i in range(len(bl)-1,1,-1):\n",
    "        if bl[i][\"bucket_size\"]==bl[i-2][\"bucket_size\"]: # merge two buckets\n",
    "            bl[i-2][\"bucket_size\"]=2*bl[i-2][\"bucket_size\"]\n",
    "            bl[i-2][\"timestamp\"]=bl[i-1][\"timestamp\"]\n",
    "            del bl[i-1]\n",
    "\n",
    "# counts of 1-bit in this window\n",
    "def count_dgim(filename):\n",
    "    windowsize=1000\n",
    "    timestamp=0\n",
    "    buckets_list=[]\n",
    "    with open(filename, 'r') as f:\n",
    "        while True:\n",
    "            bit=f.read(1)\n",
    "            if not bit:\n",
    "                break\n",
    "            if bit==\"1\":\n",
    "                bucket={\"bucket_size\":1,\"timestamp\":timestamp}\n",
    "                buckets_list.append(bucket)\n",
    "                timestamp=timestamp+1\n",
    "                update_buckets_list(windowsize,timestamp,buckets_list)\n",
    "            elif bit==\"0\":\n",
    "                timestamp=timestamp+1\n",
    "                update_buckets_list(windowsize,timestamp,buckets_list)\n",
    "    for i in range(len(buckets_list)):\n",
    "        sum_of_1bit_1=list(buckets_list[i][\"bucket_size\"] for i in range(len(buckets_list)))\n",
    "        sum_of_1bit=sum(sum_of_1bit_1)-buckets_list[0][\"bucket_size\"]/2\n",
    "    return sum_of_1bit\n",
    "\n",
    "sum_of_1bit=count_dgim(filename)\n",
    "\n",
    "print(\"The number of 1-bits in the current window using DGIM:\",sum_of_1bit)\n",
    "%time count_dgim(filename)\n",
    "%memit count_dgim(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-matthew",
   "metadata": {
    "papermill": {
     "duration": 0.014214,
     "end_time": "2021-04-25T17:16:13.401199",
     "exception": false,
     "start_time": "2021-04-25T17:16:13.386985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. Write a function that accurately counts the number of 1-bits in the current window, and compare the difference between its running time and space and the DGIM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funded-separate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:16:13.445362Z",
     "iopub.status.busy": "2021-04-25T17:16:13.444678Z",
     "iopub.status.idle": "2021-04-25T17:16:13.875169Z",
     "shell.execute_reply": "2021-04-25T17:16:13.873168Z"
    },
    "papermill": {
     "duration": 0.45965,
     "end_time": "2021-04-25T17:16:13.875367",
     "exception": false,
     "start_time": "2021-04-25T17:16:13.415717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate number of 1-bits in the current window: 391\n",
      "CPU times: user 41.1 ms, sys: 0 ns, total: 41.1 ms\n",
      "Wall time: 41.7 ms\n",
      "peak memory: 172.94 MiB, increment: 0.01 MiB\n"
     ]
    }
   ],
   "source": [
    "# the accurate count of 1-bits in this window\n",
    "def count_accurate(filename):\n",
    "    accurate_1bits=[]\n",
    "    sum_of_1bit_acc=0\n",
    "    sum_of_bit=0\n",
    "    windowsize=1000\n",
    "    timestamp1=1\n",
    "    with open(filename, 'r') as f:\n",
    "        while True:\n",
    "            bit=f.read(1)\n",
    "            if not bit:\n",
    "                break\n",
    "            else:\n",
    "                if bit==\"1\":\n",
    "                    accurate_1bits.append(1)\n",
    "                elif bit==\"0\":\n",
    "                    accurate_1bits.append(0)\n",
    "                if len(accurate_1bits)>1000:\n",
    "                    del accurate_1bits[0]\n",
    "    sum_of_1bit_acc=sum(accurate_1bits)\n",
    "    return sum_of_1bit_acc\n",
    "\n",
    "sum_of_1bit_acc=count_accurate(filename)\n",
    "print(\"The accurate number of 1-bits in the current window:\",sum_of_1bit_acc)\n",
    "%time count_accurate(filename)\n",
    "%memit count_accurate(filename)\n",
    "# It uses less time than DGIM with about the same space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-torture",
   "metadata": {
    "papermill": {
     "duration": 0.015396,
     "end_time": "2021-04-25T17:16:13.906752",
     "exception": false,
     "start_time": "2021-04-25T17:16:13.891356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It uses less time than DGIM with about the same space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-bermuda",
   "metadata": {
    "papermill": {
     "duration": 0.015948,
     "end_time": "2021-04-25T17:16:13.938100",
     "exception": false,
     "start_time": "2021-04-25T17:16:13.922152",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "naughty-handling",
   "metadata": {
    "papermill": {
     "duration": 0.015152,
     "end_time": "2021-04-25T17:16:13.968715",
     "exception": false,
     "start_time": "2021-04-25T17:16:13.953563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-enough",
   "metadata": {
    "papermill": {
     "duration": 0.015631,
     "end_time": "2021-04-25T17:16:13.999789",
     "exception": false,
     "start_time": "2021-04-25T17:16:13.984158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The locality sensitive hashing (LSH) algorithm is efficient in near-duplicate document detection. In this coding, you're given the *docs_for_lsh.csv*, where the documents are processed into set of k-shingles (k = 8, 9, 10). *docs_for_lsh.csv* contains 201 columns, where column 'doc_id' represents the unique id of each document, and from column '0' to column '199', each column represents a unique shingle. If a document contains a shingle ordered with **i**, then the corresponding row will have value 1 in column **'i'**, otherwise it's 0. You need to implement the LSH algorithm and ask the problems below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-massage",
   "metadata": {
    "papermill": {
     "duration": 0.015108,
     "end_time": "2021-04-25T17:16:14.030409",
     "exception": false,
     "start_time": "2021-04-25T17:16:14.015301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-exhibit",
   "metadata": {
    "papermill": {
     "duration": 0.015953,
     "end_time": "2021-04-25T17:16:14.061836",
     "exception": false,
     "start_time": "2021-04-25T17:16:14.045883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use minhash algoirthm to create signature of each document, and find 'the most similar' documents under Jaccard similarity. \n",
    "Parameters you need to determine:\n",
    "1) Length of signature (number of distinct minhash functions) *n*. Recommanded value: n > 20.\n",
    "\n",
    "2) Number of bands that divide the signature matrix *b*. Recommanded value: b > n // 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unexpected-context",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:16:14.101918Z",
     "iopub.status.busy": "2021-04-25T17:16:14.100977Z",
     "iopub.status.idle": "2021-04-25T17:16:35.115549Z",
     "shell.execute_reply": "2021-04-25T17:16:35.114471Z"
    },
    "papermill": {
     "duration": 21.037253,
     "end_time": "2021-04-25T17:16:35.115799",
     "exception": false,
     "start_time": "2021-04-25T17:16:14.078546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0  1  2  3  4  5  6  7  8  9  ...  190  191  192  193  194  195  196  \\\n",
      "doc_id                                ...                                      \n",
      "0       1  0  1  0  0  0  1  1  0  1  ...    0    0    0    0    0    0    0   \n",
      "1       1  1  0  1  0  1  1  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "2       1  0  1  0  1  1  0  1  0  0  ...    0    0    0    0    0    0    0   \n",
      "3       0  0  0  1  1  0  1  0  1  1  ...    0    0    0    0    0    0    0   \n",
      "4       0  0  1  1  1  1  0  1  0  0  ...    0    0    0    0    0    0    0   \n",
      "\n",
      "        197  198  199  \n",
      "doc_id                 \n",
      "0         0    0    0  \n",
      "1         0    0    0  \n",
      "2         0    0    0  \n",
      "3         0    0    0  \n",
      "4         0    0    0  \n",
      "\n",
      "[5 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import hashlib\n",
    "from sklearn.metrics import jaccard_score\n",
    "import scipy.spatial.distance as dist\n",
    "\n",
    "data=pd.read_csv('../input/coding2/docs_for_lsh.csv',index_col=0)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gorgeous-airfare",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:16:35.159225Z",
     "iopub.status.busy": "2021-04-25T17:16:35.158416Z",
     "iopub.status.idle": "2021-04-25T17:17:53.512147Z",
     "shell.execute_reply": "2021-04-25T17:17:53.511340Z"
    },
    "papermill": {
     "duration": 78.379108,
     "end_time": "2021-04-25T17:17:53.512331",
     "exception": false,
     "start_time": "2021-04-25T17:16:35.133223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../input/coding2/docs_for_lsh.csv\")\n",
    "data_list=[]\n",
    "for i in range(200):\n",
    "    data_list.append(data[str(i)].tolist())\n",
    "length=len(data_list[0])\n",
    "n_perms =40 # Length of signature\n",
    "n_samples=200 # Count of docs\n",
    "bands=500000 # Number of bands\n",
    "hash_functions=[] \n",
    "\n",
    "# generate random lists as hash functions\n",
    "def random_list(start,stop,length):\n",
    "    if length>=0:\n",
    "        length=int(length)\n",
    "    start, stop = (int(start), int(stop)) if start <= stop else (int(stop), int(start))\n",
    "    random_list=random.sample(range(start,stop), length)\n",
    "    return random_list\n",
    "\n",
    "for i in range(n_perms):\n",
    "    hash_functions.append(random_list(0,length,length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "criminal-lewis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:17:53.602401Z",
     "iopub.status.busy": "2021-04-25T17:17:53.581264Z",
     "iopub.status.idle": "2021-04-25T17:42:19.086334Z",
     "shell.execute_reply": "2021-04-25T17:42:19.086958Z"
    },
    "papermill": {
     "duration": 1465.558096,
     "end_time": "2021-04-25T17:42:19.087328",
     "exception": false,
     "start_time": "2021-04-25T17:17:53.529232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3  43   9   3  57   9   9   3   3  34   3   9   9   3   9   3   3   3\n",
      "   3   9   2   2   2  24   2   2   2  46  26  24   2  52   2  24   2  46\n",
      "  24   2  24  24   0  27  19   0   0   4   0   0   4   6  12   0   0   4\n",
      "   0   0   4   0   0   0   1   1  40   1  91   1   1   1  40   1  28  28\n",
      "  28   1  28   1  28  28  28   1  37  18  31  18  18  31  18  31  18  31\n",
      "  18  37  18  44  18  45  31  18  31  18  20  16  16  16  16  17  16  60\n",
      "  16  17  16  16  17  20  23  20  16  17  17  16  78  11  11   5   5  11\n",
      "   5   5  11   5   5  76   5  66   5  11   5   5   5  65  54  54  15  15\n",
      "  15  15  95  93  15  15  15  54  15  15 121  75  15  90  15  15   7   7\n",
      "   7   7  13  13   7   7   7   8   7   8   7   8   7   8   8   7  13   7\n",
      "  30  35  35  35  30  30  30  30  59  30  59  59  42  35  30  30  30  88\n",
      "  30  30]\n"
     ]
    }
   ],
   "source": [
    "#generate a signature matrix\n",
    "signature_matrix=[[] for i in range(n_perms)]\n",
    "for l in range(n_perms):\n",
    "    for i in range(n_samples):\n",
    "        min_index=length\n",
    "        for j in range(length):\n",
    "            if data_list[i][j]==1:\n",
    "                k=j\n",
    "                if hash_functions[l][k] < min_index:\n",
    "                    min_index=hash_functions[l][k]\n",
    "        signature_matrix[l].append(min_index)\n",
    "\n",
    "signature_matrix=np.array(signature_matrix)\n",
    "print(signature_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "white-cargo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:42:19.130986Z",
     "iopub.status.busy": "2021-04-25T17:42:19.130163Z",
     "iopub.status.idle": "2021-04-25T17:42:19.133946Z",
     "shell.execute_reply": "2021-04-25T17:42:19.133249Z"
    },
    "papermill": {
     "duration": 0.02995,
     "end_time": "2021-04-25T17:42:19.134110",
     "exception": false,
     "start_time": "2021-04-25T17:42:19.104160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# minHash: input a signature matrix,bands and rows of each band\n",
    "def minHash(s, b, r):\n",
    "    hash_buckets={} # a dictionary, buckets as key, docs as value\n",
    "    start,end=0,r\n",
    "    cnt=0\n",
    "    while end<=s.shape[0]:\n",
    "        cnt=cnt+1\n",
    "        for i in range(s.shape[1]):\n",
    "            hashObj=hashlib.md5()  # inserted hash\n",
    "            band=str(s[start:start+r,i])+str(cnt) # distinguish each band\n",
    "            hashObj.update(band.encode())\n",
    "            bucket=hashObj.hexdigest() # return the bucket\n",
    "            if bucket not in hash_buckets: # add a new bucket\n",
    "                hash_buckets[bucket]=[i]\n",
    "            elif i not in hash_buckets[bucket]: # add element to an existing bucket\n",
    "                hash_buckets[bucket].append(i)\n",
    "        start=start+r\n",
    "        end=end+r\n",
    "    return hash_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "together-asbestos",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:42:21.750903Z",
     "iopub.status.busy": "2021-04-25T17:42:21.733178Z",
     "iopub.status.idle": "2021-04-25T17:42:22.068165Z",
     "shell.execute_reply": "2021-04-25T17:42:22.068805Z"
    },
    "papermill": {
     "duration": 2.917774,
     "end_time": "2021-04-25T17:42:22.069034",
     "exception": false,
     "start_time": "2021-04-25T17:42:19.151260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18c92a4b95979e57f0b6fb4ce1ec872f [0]\n",
      "81208555d35bc0c40862976cd826ebf4 [1]\n",
      "8ba21865ea0aa5c0f7afb47b9751b485 [2, 12]\n",
      "36776040878af6e30c12244b01db980f [3, 7]\n",
      "dd7e6826a92573f894ca8c0189b68cba [4]\n",
      "b5b79b629fc44cdb08985fdc2a5fea24 [5, 11, 14]\n",
      "a80e63aad3b0b42bab76f2541da96306 [6]\n",
      "2996c6efe596ba957b2b027e3a2f45f1 [8, 13, 15, 16, 17, 18]\n",
      "3c8c7e575fd2f54867b820480279631a [9]\n",
      "a967cb42d47494912d43b6efd964443e [10]\n",
      "\n",
      "The most similar score: 0.868421052631579\n",
      "The most similar pairs: [(3, 11)]\n"
     ]
    }
   ],
   "source": [
    "# get the hash_buckets, 500000 bands\n",
    "minhash=minHash(signature_matrix,500000,2) \n",
    "sig_matrix_T=signature_matrix.T\n",
    "\n",
    "# show the top 10 hash_buckets\n",
    "for i, (k, v) in enumerate(minhash.items()):\n",
    "    if i in range(0, 10):\n",
    "        print(k, v)\n",
    "\n",
    "# calculate the similarity of each two docs in one bucket\n",
    "similar_matrix=np.array(np.zeros([n_samples,n_samples]))\n",
    "for value in minhash.values():\n",
    "    temp=value\n",
    "    if len(temp)>1:\n",
    "        for i in range(0, len(temp)):\n",
    "            for j in range(i + 1, len(temp)): # for each two docs in one bucket\n",
    "                matv = np.array([sig_matrix_T[temp[i]],sig_matrix_T[temp[j]]])\n",
    "                ds=dist.pdist(matv,'jaccard') # Jaccard similarity\n",
    "                similar_matrix[temp[i]][temp[j]]=ds\n",
    "print('')\n",
    "print(\"The most similar score:\",similar_matrix.max()) # the most similar pairs\n",
    "similar_pairs_loc=np.where(similar_matrix==similar_matrix.max())\n",
    "pairs=[]\n",
    "for i in range(len(similar_pairs_loc[0])):\n",
    "    pairs.append((similar_pairs_loc[0][i],similar_pairs_loc[1][i]))\n",
    "print(\"The most similar pairs:\",pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-label",
   "metadata": {
    "papermill": {
     "duration": 0.016746,
     "end_time": "2021-04-25T17:42:22.103182",
     "exception": false,
     "start_time": "2021-04-25T17:42:22.086436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Problem: For document 0 (the one with id '0'), list the **30** most similar document ids (except document 0 itself). You can valid your results with the [sklearn.metrics.jaccard_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html) function.\n",
    "\n",
    "Tips: You can adjust your parameters to hash the documents with similarity *s > 0.8* into the same bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "failing-mambo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T17:42:22.144709Z",
     "iopub.status.busy": "2021-04-25T17:42:22.143728Z",
     "iopub.status.idle": "2021-04-25T17:42:22.163876Z",
     "shell.execute_reply": "2021-04-25T17:42:22.164725Z"
    },
    "papermill": {
     "duration": 0.044848,
     "end_time": "2021-04-25T17:42:22.165009",
     "exception": false,
     "start_time": "2021-04-25T17:42:22.120161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 30 most similar document ids to document 0:\n",
      "Document 17  with similarity score 0.7894736842105263\n",
      "Document 2  with similarity score 0.7894736842105263\n",
      "Document 12  with similarity score 0.7837837837837838\n",
      "Document 19  with similarity score 0.7631578947368421\n",
      "Document 16  with similarity score 0.7567567567567568\n",
      "Document 1  with similarity score 0.725\n",
      "Document 3  with similarity score 0.717948717948718\n",
      "Document 6  with similarity score 0.7105263157894737\n",
      "Document 18  with similarity score 0.6842105263157895\n",
      "Document 15  with similarity score 0.6756756756756757\n",
      "Document 4  with similarity score 0.675\n",
      "Document 5  with similarity score 0.6666666666666666\n",
      "Document 10  with similarity score 0.6578947368421053\n",
      "Document 13  with similarity score 0.6486486486486487\n",
      "Document 8  with similarity score 0.6410256410256411\n",
      "Document 11  with similarity score 0.6216216216216216\n",
      "Document 14  with similarity score 0.5384615384615384\n",
      "Document 68  with similarity score 0.0\n",
      "Document 75  with similarity score 0.0\n",
      "Document 74  with similarity score 0.0\n",
      "Document 76  with similarity score 0.0\n",
      "Document 73  with similarity score 0.0\n",
      "Document 72  with similarity score 0.0\n",
      "Document 71  with similarity score 0.0\n",
      "Document 70  with similarity score 0.0\n",
      "Document 69  with similarity score 0.0\n",
      "Document 199  with similarity score 0.0\n",
      "Document 67  with similarity score 0.0\n",
      "Document 66  with similarity score 0.0\n",
      "Document 65  with similarity score 0.0\n"
     ]
    }
   ],
   "source": [
    "similar_pairs_for_zero=list(similar_matrix[0])\n",
    "sort_for_zero=np.argsort(similar_pairs_for_zero)[::-1]\n",
    "result=sort_for_zero[0:30]\n",
    "print(\"The 30 most similar document ids to document 0:\")\n",
    "for i in range(30):\n",
    "    print(\"Document\",result[i],\" with similarity score\",similar_matrix[0][result[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1590.17598,
   "end_time": "2021-04-25T17:42:27.399064",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-25T17:15:57.223084",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

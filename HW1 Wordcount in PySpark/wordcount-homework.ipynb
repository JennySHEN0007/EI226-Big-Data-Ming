{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPt5q27L5557",
    "papermill": {
     "duration": 0.011773,
     "end_time": "2021-03-15T13:25:53.599689",
     "exception": false,
     "start_time": "2021-03-15T13:25:53.587916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* > # EE226 - Coding 1\n",
    "## Wordcount in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0-YhEpP_Ds-",
    "papermill": {
     "duration": 0.010478,
     "end_time": "2021-03-15T13:25:53.621190",
     "exception": false,
     "start_time": "2021-03-15T13:25:53.610712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zsj5WYpR9QId",
    "papermill": {
     "duration": 0.010341,
     "end_time": "2021-03-15T13:25:53.642491",
     "exception": false,
     "start_time": "2021-03-15T13:25:53.632150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's setup Spark on your Kaggle environment.  Run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:25:53.672634Z",
     "iopub.status.busy": "2021-03-15T13:25:53.671956Z",
     "iopub.status.idle": "2021-03-15T13:26:33.084911Z",
     "shell.execute_reply": "2021-03-15T13:26:33.084306Z"
    },
    "id": "k-qHai2252mI",
    "outputId": "e413f50f-0e68-4d1a-8c76-eef235f3e29c",
    "papermill": {
     "duration": 39.431551,
     "end_time": "2021-03-15T13:26:33.085044",
     "exception": false,
     "start_time": "2021-03-15T13:25:53.653493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.1.1.tar.gz (212.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 212.3 MB 14 kB/s \r\n",
      "\u001b[?25hCollecting py4j==0.10.9\r\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 198 kB 40.2 MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=6c5aff08bd9db583b1d8eb4af32b662055042b8bb09990d958f18fef1abb94f8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/47/42/bc413c760cf9d3f7b46ab7cd6590e8c47ebfd19a7386cd4a57\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.1\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:26:33.349792Z",
     "iopub.status.busy": "2021-03-15T13:26:33.349108Z",
     "iopub.status.idle": "2021-03-15T13:26:38.303757Z",
     "shell.execute_reply": "2021-03-15T13:26:38.302670Z"
    },
    "id": "xu-e7Ph2_ruG",
    "papermill": {
     "duration": 5.090231,
     "end_time": "2021-03-15T13:26:38.303893",
     "exception": false,
     "start_time": "2021-03-15T13:26:33.213662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "import pandas as pd\n",
    "\n",
    "# Create the Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# The optional settings are shown below.\n",
    "\n",
    "# spark = SparkSession.builder\\\n",
    "#         .master(\"local[4]\")\\\n",
    "#         .appName(\"pyspark_study\")\\\n",
    "#         .config(\"spark.driver.memory\",\"1g\")\\\n",
    "#         .config(\"spark.executor.memory\",\"1g\")\\\n",
    "#         .config(\"spark.executor.cores\",\"2\")\\\n",
    "#         .config(\"spark.cores.max\",\"5\")\\\n",
    "#         .getOrCreate()\n",
    "\n",
    "# Create the Spark Context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:26:38.566180Z",
     "iopub.status.busy": "2021-03-15T13:26:38.565105Z",
     "iopub.status.idle": "2021-03-15T13:26:39.392993Z",
     "shell.execute_reply": "2021-03-15T13:26:39.393825Z"
    },
    "id": "AuAxGFPFB43Y",
    "outputId": "a29a9083-7fa1-45b7-f9dc-d0a654ac9721",
    "papermill": {
     "duration": 0.962625,
     "end_time": "2021-03-15T13:26:39.394032",
     "exception": false,
     "start_time": "2021-03-15T13:26:38.431407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://312e49674669:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9badd73d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the spark environment, the spark version in Kaggle is 3.1.1\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:26:39.663350Z",
     "iopub.status.busy": "2021-03-15T13:26:39.662435Z",
     "iopub.status.idle": "2021-03-15T13:26:44.170294Z",
     "shell.execute_reply": "2021-03-15T13:26:44.168965Z"
    },
    "id": "A-SSxDs9FdJa",
    "outputId": "8a426c52-caca-4e9e-bacf-3afefe48abba",
    "papermill": {
     "duration": 4.644528,
     "end_time": "2021-03-15T13:26:44.170515",
     "exception": false,
     "start_time": "2021-03-15T13:26:39.525987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|0.000123, which c...|\n",
      "|000webhost is a f...|\n",
      "|0010x0010 is a Du...|\n",
      "|0-0-1-3 is an alc...|\n",
      "|0.01 is the debut...|\n",
      "|001 of 3 February...|\n",
      "|003230 is a South...|\n",
      "|0.04%Gas molecule...|\n",
      "|0.04% of the vote...|\n",
      "|005.1999.06 is th...|\n",
      "|005 is a 1981 arc...|\n",
      "|007 Legends is a ...|\n",
      "|007 Legends is th...|\n",
      "|007 Racing is a r...|\n",
      "|00 AM PST and bur...|\n",
      "|00am to 1:00pm on...|\n",
      "|0.0 is a live alb...|\n",
      "|0.0% is considere...|\n",
      "|00 pm in daily go...|\n",
      "|00 - The rebels s...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset, and generate a dataframe with one column \"value\", where each row contains a set of words\n",
    "text = spark.read.text(\"../input/wikipedia-sentences/wikisent2.txt\")\n",
    "text.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.125892,
     "end_time": "2021-03-15T13:26:44.430966",
     "exception": false,
     "start_time": "2021-03-15T13:26:44.305074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you run successfully the setup stage, you are ready to work on the dataframe *text* generated from *wikisent2.txt* file which contains a copy of the sentences in Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRaF2A_j_nC7",
    "papermill": {
     "duration": 0.126074,
     "end_time": "2021-03-15T13:26:44.683505",
     "exception": false,
     "start_time": "2021-03-15T13:26:44.557431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebLNUxP0_8x3",
    "papermill": {
     "duration": 0.126277,
     "end_time": "2021-03-15T13:26:44.936548",
     "exception": false,
     "start_time": "2021-03-15T13:26:44.810271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Write a Spark application which outputs the number of each words. In your implementation **ignore the letter case**, i.e., you need to process all words to lower case. Also, you can ignore all the words **starting** with a non-alphabetic character.\n",
    "\n",
    "**Tips**: you'd better preprocess the dataset, i.e., remove the punctuations and numbers (0-9) to make your work effective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:26:45.198381Z",
     "iopub.status.busy": "2021-03-15T13:26:45.197632Z",
     "iopub.status.idle": "2021-03-15T13:26:46.115430Z",
     "shell.execute_reply": "2021-03-15T13:26:46.114462Z"
    },
    "id": "R24ZBGUgTLJP",
    "papermill": {
     "duration": 1.051904,
     "end_time": "2021-03-15T13:26:46.115601",
     "exception": false,
     "start_time": "2021-03-15T13:26:45.063697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "+-----------+\n",
      "|      value|\n",
      "+-----------+\n",
      "|      which|\n",
      "|corresponds|\n",
      "|         to|\n",
      "|          a|\n",
      "|   distance|\n",
      "|         of|\n",
      "|        mly|\n",
      "|         or|\n",
      "|        mpc|\n",
      "|         is|\n",
      "|          a|\n",
      "|       free|\n",
      "|        web|\n",
      "|    hosting|\n",
      "|    service|\n",
      "|   operated|\n",
      "|         by|\n",
      "|  hostinger|\n",
      "|         is|\n",
      "|          a|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change to lower case\n",
    "text1=text.select(lower('value'))\n",
    "text1=text1.withColumnRenamed(\"lower(value)\",'value')\n",
    "df=text1\n",
    "df.printSchema()\n",
    "\n",
    "# split each word with a space\n",
    "df1=df.withColumn(\"value_1\",explode(split('value',\" \")))\n",
    "\n",
    "# omit the punctuations immediately next to a word\n",
    "df2=df1.select(\"value_1\", f.regexp_replace(f.col(\"value_1\"), \"[,.]\", \"\").alias(\"value\"))\n",
    "df2=df2.drop(\"value_1\")\n",
    "\n",
    "# omit non-alphabetic words and some unique characters\n",
    "#df3=df2.filter(df2.value.contains(\"0\")==False)\n",
    "df3=df2.filter(df2.value.rlike('^[a-z]+$'))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:26:46.391439Z",
     "iopub.status.busy": "2021-03-15T13:26:46.390283Z",
     "iopub.status.idle": "2021-03-15T13:33:02.179812Z",
     "shell.execute_reply": "2021-03-15T13:33:02.181307Z"
    },
    "id": "dVRKJ9VtcwSM",
    "outputId": "c594f5c4-ccf2-4355-9632-206f234ce343",
    "papermill": {
     "duration": 375.930301,
     "end_time": "2021-03-15T13:33:02.181824",
     "exception": false,
     "start_time": "2021-03-15T13:26:46.251523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|     value| count|\n",
      "+----------+------+\n",
      "|  distance|  9272|\n",
      "|        an|852941|\n",
      "|         e| 15227|\n",
      "|   college| 95203|\n",
      "|     debut| 49805|\n",
      "|     album|242591|\n",
      "|    korean| 12428|\n",
      "|       uhm|    18|\n",
      "|      sega|  2019|\n",
      "| featuring| 19318|\n",
      "|    fourth| 30012|\n",
      "|operations| 19499|\n",
      "|      home| 61414|\n",
      "|   biggest|  6470|\n",
      "|     bunch|   461|\n",
      "|   talents|  1009|\n",
      "|      live| 46764|\n",
      "|   perform|  7004|\n",
      "|      name|128629|\n",
      "|      they|178412|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# implement map and reduce\n",
    "output = df3.rdd.map(lambda x: (x, 1)).reduceByKey(lambda a, b: a + b)\n",
    "output=output.toDF()\n",
    "\n",
    "# change the type of elements in column 1\n",
    "output=output.withColumn(\"_1\",output[\"_1\"].cast(StringType()))\n",
    "output=output.select( f.regexp_replace(f.col(\"_1\"), \"[{}]\", \"\").alias(\"value\"),\"_2\")\n",
    "output=output.withColumnRenamed(\"_2\",'count')\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.178876,
     "end_time": "2021-03-15T13:33:02.548257",
     "exception": false,
     "start_time": "2021-03-15T13:33:02.369381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. After wordcounting, you need to solve the problems below.\n",
    "\n",
    "The use of `dataframe` is recommended, you can convert your count list to spark dataframe, and apply related functions to get the results easily.\n",
    "\n",
    "1) Which word appears the most? Write code to output your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:33:02.913476Z",
     "iopub.status.busy": "2021-03-15T13:33:02.912395Z",
     "iopub.status.idle": "2021-03-15T13:33:25.423757Z",
     "shell.execute_reply": "2021-03-15T13:33:25.424849Z"
    },
    "papermill": {
     "duration": 22.705798,
     "end_time": "2021-03-15T13:33:25.425453",
     "exception": false,
     "start_time": "2021-03-15T13:33:02.719655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|value|   count|\n",
      "+-----+--------+\n",
      "|  the|10783122|\n",
      "+-----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cache for speed\n",
    "output.cache()\n",
    "\n",
    "# sort by descending orders and choose the top 1\n",
    "sorted_output=output.sort(desc(\"count\"))\n",
    "sorted_output.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.130725,
     "end_time": "2021-03-15T13:33:25.697476",
     "exception": false,
     "start_time": "2021-03-15T13:33:25.566751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2) How many times does the word ‘China’ appear? Write code to output your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:33:25.965876Z",
     "iopub.status.busy": "2021-03-15T13:33:25.964814Z",
     "iopub.status.idle": "2021-03-15T13:33:26.916601Z",
     "shell.execute_reply": "2021-03-15T13:33:26.915468Z"
    },
    "papermill": {
     "duration": 1.088888,
     "end_time": "2021-03-15T13:33:26.916872",
     "exception": false,
     "start_time": "2021-03-15T13:33:25.827984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|value|count|\n",
      "+-----+-----+\n",
      "|china|27632|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "china_appear=output.where(\"value=='china'\")\n",
    "china_appear.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.142364,
     "end_time": "2021-03-15T13:33:27.202987",
     "exception": false,
     "start_time": "2021-03-15T13:33:27.060623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3) Write a block which outputs the number of words that start with each letter (a - z). This means that for every letter we want to count the total number of (non-unique) words that start with a specific letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-15T13:33:27.489728Z",
     "iopub.status.busy": "2021-03-15T13:33:27.488756Z",
     "iopub.status.idle": "2021-03-15T13:33:30.722684Z",
     "shell.execute_reply": "2021-03-15T13:33:30.721673Z"
    },
    "papermill": {
     "duration": 3.38128,
     "end_time": "2021-03-15T13:33:30.722871",
     "exception": false,
     "start_time": "2021-03-15T13:33:27.341591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|letter|   count|\n",
      "+------+--------+\n",
      "|     t|18830225|\n",
      "|     a|18589766|\n",
      "|     i|12505513|\n",
      "|     o| 9760270|\n",
      "|     s| 9733911|\n",
      "|     c| 8129109|\n",
      "|     w| 6835629|\n",
      "|     f| 6670944|\n",
      "|     b| 6565492|\n",
      "|     p| 6033054|\n",
      "|     m| 5182604|\n",
      "|     h| 4706378|\n",
      "|     r| 4493378|\n",
      "|     d| 4025353|\n",
      "|     l| 3418787|\n",
      "|     e| 3200433|\n",
      "|     n| 2944063|\n",
      "|     g| 2445425|\n",
      "|     u| 1840368|\n",
      "|     j| 1235458|\n",
      "|     v| 1191023|\n",
      "|     k| 1070563|\n",
      "|     y|  520885|\n",
      "|     q|  178096|\n",
      "|     z|  145912|\n",
      "|     x|   44150|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract the first character of each word\n",
    "extracted_letter=output.select(substring(output.value, 1,1).alias('s'),\"count\")\n",
    "\n",
    "# implement map and reduce which uses the letter as the key and the count as the value\n",
    "letter_startwith =extracted_letter.rdd.map(lambda x: (x[0], x[1])).reduceByKey(lambda a, b: a + b)\n",
    "letter_startwith=letter_startwith.toDF()\n",
    "letter_startwith=letter_startwith.withColumnRenamed(\"_1\",\"letter\")\n",
    "letter_startwith=letter_startwith.withColumnRenamed(\"_2\",\"count\")\n",
    "letter_startwith.sort(desc('count')).show(26)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "duration": 462.024812,
   "end_time": "2021-03-15T13:33:31.027595",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-15T13:25:49.002783",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
